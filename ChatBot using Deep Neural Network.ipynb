{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Using Deep Neural Network***"
      ],
      "metadata": {
        "id": "70DBB1YFSpC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ],
      "metadata": {
        "id": "WkRRngByRIZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversations = [\n",
        "    (\"Hi!\", \"Hello!\"),\n",
        "    (\"How are you?\", \"I'm good, thank you.\"),\n",
        "    (\"What's your name?\", \"I'm a chatbot.\"),\n",
        "    (\"Where are you from?\", \"I exist in the digital realm.\"),\n",
        "    (\"What can you do?\", \"I can assist you with information and answer your questions.\"),\n",
        "    (\"How old are you?\", \"I don't have an age. I'm just a computer program.\"),\n",
        "    (\"Do you have any hobbies?\", \"I don't have hobbies, but I enjoy helping users like you!\"),\n",
        "    (\"Can you tell a joke?\", \"Sure, here's one: Why don't scientists trust atoms? Because they make up everything!\"),\n",
        "    (\"What's the meaning of life?\", \"That's a deep question! The meaning of life can vary from person to person.\"),\n",
        "    # Add more conversation pairs as needed\n",
        "]"
      ],
      "metadata": {
        "id": "X-1iSL_aTrDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "questions, answers = zip(*conversations)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "question_seq = tokenizer.texts_to_sequences(questions)\n",
        "answer_seq = tokenizer.texts_to_sequences(answers)\n",
        "\n",
        "max_len = max(len(seq) for seq in question_seq + answer_seq)\n",
        "question_seq = pad_sequences(question_seq, maxlen=max_len, padding='post')\n",
        "answer_seq = pad_sequences(answer_seq, maxlen=max_len, padding='post')"
      ],
      "metadata": {
        "id": "qmPy3LGtTrBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "embedding_dim = 100\n",
        "units = 256\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_len),\n",
        "    Bidirectional(LSTM(units, return_sequences=True)),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rWNcOsJUTq-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(question_seq, np.expand_dims(answer_seq, -1), epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBRd3MG5Tq7_",
        "outputId": "1f7b2edf-969d-4b26-8122-8c114d76a84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 5s - loss: 4.2346 - accuracy: 0.0079 - 5s/epoch - 5s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 4.1863 - accuracy: 0.4286 - 86ms/epoch - 86ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 4.1349 - accuracy: 0.4286 - 78ms/epoch - 78ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 4.0739 - accuracy: 0.4286 - 83ms/epoch - 83ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 3.9953 - accuracy: 0.4286 - 83ms/epoch - 83ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 3.8876 - accuracy: 0.4286 - 85ms/epoch - 85ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 3.7333 - accuracy: 0.4286 - 87ms/epoch - 87ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 3.5092 - accuracy: 0.4286 - 92ms/epoch - 92ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 3.2197 - accuracy: 0.4286 - 106ms/epoch - 106ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 3.0103 - accuracy: 0.4286 - 85ms/epoch - 85ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.8045 - accuracy: 0.4286 - 93ms/epoch - 93ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.7556 - accuracy: 0.4286 - 86ms/epoch - 86ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.7847 - accuracy: 0.4286 - 91ms/epoch - 91ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.7884 - accuracy: 0.4286 - 72ms/epoch - 72ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.7495 - accuracy: 0.4286 - 77ms/epoch - 77ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.6871 - accuracy: 0.4286 - 118ms/epoch - 118ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.6231 - accuracy: 0.4286 - 75ms/epoch - 75ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.5714 - accuracy: 0.4444 - 74ms/epoch - 74ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.5342 - accuracy: 0.4603 - 75ms/epoch - 75ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.5050 - accuracy: 0.4603 - 81ms/epoch - 81ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.4756 - accuracy: 0.4603 - 80ms/epoch - 80ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.4438 - accuracy: 0.4603 - 76ms/epoch - 76ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.4143 - accuracy: 0.4603 - 84ms/epoch - 84ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 2.3934 - accuracy: 0.4603 - 79ms/epoch - 79ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 2.3806 - accuracy: 0.4603 - 94ms/epoch - 94ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 2.3698 - accuracy: 0.4603 - 78ms/epoch - 78ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 2.3555 - accuracy: 0.4603 - 76ms/epoch - 76ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 2.3359 - accuracy: 0.4603 - 75ms/epoch - 75ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 2.3124 - accuracy: 0.4524 - 73ms/epoch - 73ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 2.2876 - accuracy: 0.4524 - 79ms/epoch - 79ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 2.2640 - accuracy: 0.4524 - 85ms/epoch - 85ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 2.2433 - accuracy: 0.4524 - 82ms/epoch - 82ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 2.2261 - accuracy: 0.4524 - 81ms/epoch - 81ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 2.2120 - accuracy: 0.4524 - 81ms/epoch - 81ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 2.1996 - accuracy: 0.4603 - 72ms/epoch - 72ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 2.1871 - accuracy: 0.4683 - 78ms/epoch - 78ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 2.1733 - accuracy: 0.4683 - 89ms/epoch - 89ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 2.1572 - accuracy: 0.4683 - 68ms/epoch - 68ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 2.1393 - accuracy: 0.4683 - 72ms/epoch - 72ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 2.1209 - accuracy: 0.4683 - 81ms/epoch - 81ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 2.1035 - accuracy: 0.4683 - 88ms/epoch - 88ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 2.0878 - accuracy: 0.4683 - 84ms/epoch - 84ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 2.0731 - accuracy: 0.4683 - 74ms/epoch - 74ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 2.0578 - accuracy: 0.4683 - 127ms/epoch - 127ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 2.0407 - accuracy: 0.4683 - 129ms/epoch - 129ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 2.0222 - accuracy: 0.4683 - 131ms/epoch - 131ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 2.0049 - accuracy: 0.4683 - 182ms/epoch - 182ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.9913 - accuracy: 0.4683 - 176ms/epoch - 176ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.9773 - accuracy: 0.4762 - 158ms/epoch - 158ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.9586 - accuracy: 0.4762 - 131ms/epoch - 131ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.9408 - accuracy: 0.4762 - 137ms/epoch - 137ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.9262 - accuracy: 0.4762 - 116ms/epoch - 116ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.9087 - accuracy: 0.4762 - 162ms/epoch - 162ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.8882 - accuracy: 0.4683 - 158ms/epoch - 158ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.8727 - accuracy: 0.4683 - 136ms/epoch - 136ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.8546 - accuracy: 0.4683 - 169ms/epoch - 169ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.8342 - accuracy: 0.4683 - 144ms/epoch - 144ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.8180 - accuracy: 0.4683 - 143ms/epoch - 143ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.7960 - accuracy: 0.4683 - 149ms/epoch - 149ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.7806 - accuracy: 0.4841 - 177ms/epoch - 177ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.7572 - accuracy: 0.4762 - 174ms/epoch - 174ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.7403 - accuracy: 0.4683 - 158ms/epoch - 158ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.7191 - accuracy: 0.4921 - 142ms/epoch - 142ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.6982 - accuracy: 0.4921 - 139ms/epoch - 139ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.6810 - accuracy: 0.4762 - 110ms/epoch - 110ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.6614 - accuracy: 0.5079 - 200ms/epoch - 200ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.6417 - accuracy: 0.4921 - 167ms/epoch - 167ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.6177 - accuracy: 0.5317 - 191ms/epoch - 191ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.5949 - accuracy: 0.5159 - 132ms/epoch - 132ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.5726 - accuracy: 0.5556 - 146ms/epoch - 146ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.5520 - accuracy: 0.5556 - 129ms/epoch - 129ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.5378 - accuracy: 0.6032 - 162ms/epoch - 162ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.5537 - accuracy: 0.5317 - 167ms/epoch - 167ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.5006 - accuracy: 0.6032 - 161ms/epoch - 161ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.4608 - accuracy: 0.5873 - 185ms/epoch - 185ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.4516 - accuracy: 0.5635 - 150ms/epoch - 150ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 1.4313 - accuracy: 0.6111 - 116ms/epoch - 116ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 1.3985 - accuracy: 0.5952 - 91ms/epoch - 91ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 1.3721 - accuracy: 0.6111 - 99ms/epoch - 99ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 1.3613 - accuracy: 0.6270 - 103ms/epoch - 103ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 1.3457 - accuracy: 0.5873 - 139ms/epoch - 139ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 1.3063 - accuracy: 0.6270 - 137ms/epoch - 137ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 1.2870 - accuracy: 0.6587 - 116ms/epoch - 116ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 1.2814 - accuracy: 0.6270 - 115ms/epoch - 115ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 1.2500 - accuracy: 0.6825 - 120ms/epoch - 120ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 1.2176 - accuracy: 0.6905 - 118ms/epoch - 118ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 1.1975 - accuracy: 0.7143 - 143ms/epoch - 143ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 1.1861 - accuracy: 0.7302 - 111ms/epoch - 111ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 1.1753 - accuracy: 0.6825 - 107ms/epoch - 107ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 1.1425 - accuracy: 0.7460 - 118ms/epoch - 118ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 1.1127 - accuracy: 0.7063 - 99ms/epoch - 99ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 1.0933 - accuracy: 0.7063 - 99ms/epoch - 99ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 1.0820 - accuracy: 0.7381 - 99ms/epoch - 99ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 1.0752 - accuracy: 0.7063 - 107ms/epoch - 107ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 1.0506 - accuracy: 0.7460 - 129ms/epoch - 129ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 1.0220 - accuracy: 0.7302 - 120ms/epoch - 120ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.9922 - accuracy: 0.7857 - 120ms/epoch - 120ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.9758 - accuracy: 0.7937 - 135ms/epoch - 135ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.9682 - accuracy: 0.7460 - 144ms/epoch - 144ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.9532 - accuracy: 0.8016 - 144ms/epoch - 144ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.9333 - accuracy: 0.7857 - 162ms/epoch - 162ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.9020 - accuracy: 0.8492 - 155ms/epoch - 155ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.8789 - accuracy: 0.8571 - 127ms/epoch - 127ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.8671 - accuracy: 0.8492 - 72ms/epoch - 72ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.8584 - accuracy: 0.8413 - 75ms/epoch - 75ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.8489 - accuracy: 0.8254 - 99ms/epoch - 99ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.8246 - accuracy: 0.8571 - 86ms/epoch - 86ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.7945 - accuracy: 0.8730 - 89ms/epoch - 89ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.7750 - accuracy: 0.8889 - 80ms/epoch - 80ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.7646 - accuracy: 0.8889 - 81ms/epoch - 81ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.7541 - accuracy: 0.8968 - 95ms/epoch - 95ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.7355 - accuracy: 0.9048 - 95ms/epoch - 95ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.7107 - accuracy: 0.9048 - 81ms/epoch - 81ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.6863 - accuracy: 0.9286 - 86ms/epoch - 86ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.6735 - accuracy: 0.9206 - 83ms/epoch - 83ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.6579 - accuracy: 0.9286 - 78ms/epoch - 78ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.6352 - accuracy: 0.9524 - 95ms/epoch - 95ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.6222 - accuracy: 0.9206 - 77ms/epoch - 77ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.6159 - accuracy: 0.9286 - 73ms/epoch - 73ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.5999 - accuracy: 0.9206 - 85ms/epoch - 85ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.6003 - accuracy: 0.9206 - 84ms/epoch - 84ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.6396 - accuracy: 0.8730 - 83ms/epoch - 83ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.6494 - accuracy: 0.9286 - 78ms/epoch - 78ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.6046 - accuracy: 0.8810 - 79ms/epoch - 79ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.5154 - accuracy: 0.9365 - 84ms/epoch - 84ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.5664 - accuracy: 0.9365 - 112ms/epoch - 112ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.5181 - accuracy: 0.9206 - 91ms/epoch - 91ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.5058 - accuracy: 0.9286 - 82ms/epoch - 82ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.4944 - accuracy: 0.9444 - 83ms/epoch - 83ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.4604 - accuracy: 0.9524 - 85ms/epoch - 85ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.4583 - accuracy: 0.9524 - 78ms/epoch - 78ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.4297 - accuracy: 0.9841 - 83ms/epoch - 83ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.4267 - accuracy: 0.9524 - 86ms/epoch - 86ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.4046 - accuracy: 0.9524 - 92ms/epoch - 92ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.3988 - accuracy: 0.9683 - 100ms/epoch - 100ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.3816 - accuracy: 0.9921 - 78ms/epoch - 78ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.3718 - accuracy: 0.9683 - 107ms/epoch - 107ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.3614 - accuracy: 0.9762 - 89ms/epoch - 89ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.3447 - accuracy: 0.9841 - 82ms/epoch - 82ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.3399 - accuracy: 0.9841 - 66ms/epoch - 66ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.3207 - accuracy: 0.9921 - 70ms/epoch - 70ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.3180 - accuracy: 0.9762 - 70ms/epoch - 70ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.3011 - accuracy: 0.9841 - 64ms/epoch - 64ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.2961 - accuracy: 0.9921 - 65ms/epoch - 65ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.2832 - accuracy: 1.0000 - 65ms/epoch - 65ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.2746 - accuracy: 0.9921 - 74ms/epoch - 74ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.2664 - accuracy: 0.9921 - 72ms/epoch - 72ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.2559 - accuracy: 1.0000 - 73ms/epoch - 73ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.2501 - accuracy: 1.0000 - 65ms/epoch - 65ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.2393 - accuracy: 1.0000 - 85ms/epoch - 85ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.2334 - accuracy: 1.0000 - 65ms/epoch - 65ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2245 - accuracy: 1.0000 - 78ms/epoch - 78ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2177 - accuracy: 1.0000 - 81ms/epoch - 81ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2108 - accuracy: 1.0000 - 90ms/epoch - 90ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2029 - accuracy: 1.0000 - 80ms/epoch - 80ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.1979 - accuracy: 1.0000 - 78ms/epoch - 78ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.1897 - accuracy: 1.0000 - 94ms/epoch - 94ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.1853 - accuracy: 1.0000 - 96ms/epoch - 96ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.1777 - accuracy: 1.0000 - 93ms/epoch - 93ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.1732 - accuracy: 1.0000 - 77ms/epoch - 77ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.1668 - accuracy: 1.0000 - 83ms/epoch - 83ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.1618 - accuracy: 1.0000 - 95ms/epoch - 95ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.1567 - accuracy: 1.0000 - 85ms/epoch - 85ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.1513 - accuracy: 1.0000 - 75ms/epoch - 75ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.1471 - accuracy: 1.0000 - 82ms/epoch - 82ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.1418 - accuracy: 1.0000 - 81ms/epoch - 81ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.1381 - accuracy: 1.0000 - 85ms/epoch - 85ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.1333 - accuracy: 1.0000 - 78ms/epoch - 78ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.1294 - accuracy: 1.0000 - 93ms/epoch - 93ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.1254 - accuracy: 1.0000 - 83ms/epoch - 83ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.1215 - accuracy: 1.0000 - 77ms/epoch - 77ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1181 - accuracy: 1.0000 - 78ms/epoch - 78ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1143 - accuracy: 1.0000 - 73ms/epoch - 73ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1111 - accuracy: 1.0000 - 96ms/epoch - 96ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1077 - accuracy: 1.0000 - 69ms/epoch - 69ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1047 - accuracy: 1.0000 - 74ms/epoch - 74ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1016 - accuracy: 1.0000 - 74ms/epoch - 74ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.0988 - accuracy: 1.0000 - 80ms/epoch - 80ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.0960 - accuracy: 1.0000 - 88ms/epoch - 88ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.0933 - accuracy: 1.0000 - 85ms/epoch - 85ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.0908 - accuracy: 1.0000 - 87ms/epoch - 87ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.0882 - accuracy: 1.0000 - 95ms/epoch - 95ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.0860 - accuracy: 1.0000 - 75ms/epoch - 75ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.0837 - accuracy: 1.0000 - 74ms/epoch - 74ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.0814 - accuracy: 1.0000 - 100ms/epoch - 100ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.0794 - accuracy: 1.0000 - 103ms/epoch - 103ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.0773 - accuracy: 1.0000 - 73ms/epoch - 73ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.0754 - accuracy: 1.0000 - 67ms/epoch - 67ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.0735 - accuracy: 1.0000 - 75ms/epoch - 75ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.0717 - accuracy: 1.0000 - 85ms/epoch - 85ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.0699 - accuracy: 1.0000 - 75ms/epoch - 75ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.0682 - accuracy: 1.0000 - 70ms/epoch - 70ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.0667 - accuracy: 1.0000 - 85ms/epoch - 85ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.0651 - accuracy: 1.0000 - 70ms/epoch - 70ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.0636 - accuracy: 1.0000 - 64ms/epoch - 64ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.0621 - accuracy: 1.0000 - 70ms/epoch - 70ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.0607 - accuracy: 1.0000 - 75ms/epoch - 75ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.0594 - accuracy: 1.0000 - 89ms/epoch - 89ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.0581 - accuracy: 1.0000 - 74ms/epoch - 74ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.0568 - accuracy: 1.0000 - 81ms/epoch - 81ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78f38834be80>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate response\n",
        "def generate_response(question):\n",
        "    question_seq = tokenizer.texts_to_sequences([question])\n",
        "    question_seq = pad_sequences(question_seq, maxlen=max_len, padding='post')\n",
        "    predicted_answer_seq = model.predict(question_seq)\n",
        "    predicted_answer = tokenizer.sequences_to_texts(np.argmax(predicted_answer_seq, axis=2))\n",
        "    return predicted_answer[0]"
      ],
      "metadata": {
        "id": "YXHT_l-rTq5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to start the chatbot\n",
        "def chatbot():\n",
        "    print(\"Hi! I'm an Chatbot. How can I assist you today?\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"quit\":\n",
        "            print(\"Bot: Bye, take care. See you soon!\")\n",
        "            break\n",
        "        response = generate_response(user_input)\n",
        "        print(\"Bot:\", response)"
      ],
      "metadata": {
        "id": "zcafzTBDT29U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chatbot\n",
        "chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-dk90h8TSbu",
        "outputId": "4af11d1d-a7b9-4d7b-f2ea-56038c1b813d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi! I'm an Chatbot. How can I assist you today?\n",
            "You: Hii\n",
            "1/1 [==============================] - 1s 890ms/step\n",
            "Bot: i'm a chatbot\n",
            "You: Where are you from?\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Bot: i exist in the digital realm\n",
            "You: What can you do for me?\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Bot: i can assist you with information and answer your questions\n",
            "You: How are you?\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Bot: i'm good thank you\n",
            "You: Do you have any hobbies?\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Bot: i don't have hobbies but i enjoy helping users like you\n",
            "You: Please tell me a joke\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Bot: i don't have hobbies but i enjoy helping users computer program\n",
            "You: Tell me a joke\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Bot: i don't have hobbies but i enjoy helping users computer program\n",
            "You: Can you tell me a joke?\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Bot: sure here's one why don't scientists trust atoms because they make up everything\n",
            "You: How old are you?\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Bot: i don't have an age i'm just a computer program\n",
            "You: Quit\n",
            "Bot: Bye, take care. See you soon!\n"
          ]
        }
      ]
    }
  ]
}